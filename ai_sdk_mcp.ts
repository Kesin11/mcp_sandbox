import { experimental_createMCPClient, generateText } from "npm:ai";
import { Experimental_StdioMCPTransport } from "npm:ai/mcp-stdio";
import { createOpenAI } from "npm:@ai-sdk/openai";
import { createOllama } from "npm:ollama-ai-provider";
import { parseArgs } from "jsr:@std/cli/parse-args";

// ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®šã®å‹å®šç¾©
interface ProviderConfig {
  provider: "github" | "openrouter" | "ollama";
  baseURL: string;
  apiKey: string;
  model: string;
}

// ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®å‹å®šç¾©
interface ParsedArgs {
  message: string;
  provider: "github" | "openrouter" | "ollama";
  token?: string;
  model: string;
  baseUrl?: string;
  help: boolean;
}

// ãƒ˜ãƒ«ãƒ—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
function showHelp(): void {
  console.log(`
AI SDK MCP ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ - ãƒãƒ«ãƒãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å¯¾å¿œTODOã‚¿ã‚¹ã‚¯ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

ä½¿ç”¨æ–¹æ³•:
  deno run --allow-all ai_sdk_mcp.ts "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸" --model "ãƒ¢ãƒ‡ãƒ«å" [ã‚ªãƒ—ã‚·ãƒ§ãƒ³]

å¿…é ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:
  ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸            AIã«é€ä¿¡ã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆä½ç½®å¼•æ•°ï¼‰
  --model, -m          ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«åï¼ˆå¿…é ˆï¼‰

ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:
  --provider, -p       ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼é¸æŠ (github|openrouter|ollama) [ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: github]
  --token, -t          APIãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆç’°å¢ƒå¤‰æ•°ã‚ˆã‚Šå„ªå…ˆï¼‰
  --baseUrl, -b        ã‚«ã‚¹ã‚¿ãƒ baseURLï¼ˆå…¨ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å¯¾å¿œï¼‰
  --help, -h           ã“ã®ãƒ˜ãƒ«ãƒ—ã‚’è¡¨ç¤º

ç’°å¢ƒå¤‰æ•°:
  GITHUB_TOKEN         GitHub Modelsã‚¢ã‚¯ã‚»ã‚¹ç”¨ãƒˆãƒ¼ã‚¯ãƒ³
  OPENROUTER_API_KEY   OpenRouterã‚¢ã‚¯ã‚»ã‚¹ç”¨ãƒˆãƒ¼ã‚¯ãƒ³
  MAX_RETRIES          ãƒªãƒˆãƒ©ã‚¤å›æ•° [ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3]

ä½¿ç”¨ä¾‹:
  # GitHub Modelsï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
  deno run --allow-all ai_sdk_mcp.ts "ã‚¿ã‚¹ã‚¯ä½œæˆã—ã¦ãã ã•ã„" --model "openai/gpt-4.1"
  
  # GitHub Modelsã€åˆ¥ã®ãƒ¢ãƒ‡ãƒ«
  deno run --allow-all ai_sdk_mcp.ts "ã‚¿ã‚¹ã‚¯ä½œæˆ" --model "openai/gpt-4.1-mini"
  
  # OpenRouterä½¿ç”¨
  deno run --allow-all ai_sdk_mcp.ts "ã‚¿ã‚¹ã‚¯ä½œæˆ" --provider openrouter --model "openai/gpt-4"
  
  # OpenRouterã€Claudeãƒ¢ãƒ‡ãƒ«
  deno run --allow-all ai_sdk_mcp.ts "ã‚¿ã‚¹ã‚¯ä½œæˆ" --provider openrouter --model "anthropic/claude-3.5-sonnet"
  
  # Ollamaä½¿ç”¨ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰
  deno run --allow-all ai_sdk_mcp.ts "ã‚¿ã‚¹ã‚¯ä½œæˆ" --provider ollama --model "llama3.1"
  
  # Ollamaã€ã‚«ã‚¹ã‚¿ãƒ URL
  deno run --allow-all ai_sdk_mcp.ts "ã‚¿ã‚¹ã‚¯ä½œæˆ" --provider ollama --model "phi3" --baseUrl "http://remote-ollama:11434"
  
  # GitHub Modelsã€ã‚«ã‚¹ã‚¿ãƒ baseURL
  deno run --allow-all ai_sdk_mcp.ts "ã‚¿ã‚¹ã‚¯ä½œæˆ" --provider github --model "openai/gpt-4.1" --baseUrl "https://custom-github-models.example.com"
  
  # ãƒˆãƒ¼ã‚¯ãƒ³æ˜ç¤ºæŒ‡å®š
  deno run --allow-all ai_sdk_mcp.ts "ã‚¿ã‚¹ã‚¯ä½œæˆ" --provider openrouter --model "openai/gpt-4" --token "sk-xxx"

å¯¾å¿œãƒ¢ãƒ‡ãƒ«ã®ä¾‹:
  GitHub Models:
    - openai/gpt-4.1 (æ¨å¥¨)
    - openai/gpt-4.1-mini
    - meta/llama-3.3-70b-instruct
    
  OpenRouter:
    - openai/gpt-4
    - anthropic/claude-3.5-sonnet
    - meta-llama/llama-3.1-70b
    - google/gemini-pro
    
  Ollama:
    - llama3.1
    - llama3.2
    - phi3
    - mistral
    - codellama
    - gemma
`);
}

// ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’è§£æ
function parseCommandLineArgs(): ParsedArgs {
  const flags = parseArgs(Deno.args, {
    string: ["provider", "token", "model", "baseUrl"],
    boolean: ["help"],
    alias: { p: "provider", t: "token", m: "model", b: "baseUrl", h: "help" },
    default: { provider: "github" },
  });

  const message = flags._[0] as string;

  if (flags.help) {
    return {
      message: "",
      provider: "github",
      model: "",
      help: true,
    };
  }

  if (!message) {
    throw new Error("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚");
  }

  if (!flags.model) {
    throw new Error("--model ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯å¿…é ˆã§ã™ã€‚");
  }

  if (
    flags.provider !== "github" && flags.provider !== "openrouter" &&
    flags.provider !== "ollama"
  ) {
    throw new Error(
      "--provider ã¯ 'github'ã€'openrouter'ã€ã¾ãŸã¯ 'ollama' ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚",
    );
  }

  return {
    message,
    provider: flags.provider as "github" | "openrouter" | "ollama",
    token: flags.token,
    model: flags.model,
    baseUrl: flags.baseUrl,
    help: false,
  };
}

// ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®šã‚’ä½œæˆ
function createProviderConfig(args: ParsedArgs): ProviderConfig {
  switch (args.provider) {
    case "github":
      return {
        provider: "github",
        baseURL: args.baseUrl || "https://models.github.ai/inference",
        apiKey: args.token || Deno.env.get("GITHUB_TOKEN") ||
          "dummy-key-for-github-models",
        model: args.model,
      };
    case "openrouter": {
      const openrouterKey = args.token || Deno.env.get("OPENROUTER_API_KEY");
      if (!openrouterKey) {
        throw new Error(
          "OpenRouterã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€OPENROUTER_API_KEYç’°å¢ƒå¤‰æ•°ã¾ãŸã¯--tokenãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚",
        );
      }
      return {
        provider: "openrouter",
        baseURL: args.baseUrl || "https://openrouter.ai/api/v1",
        apiKey: openrouterKey,
        model: args.model,
      };
    }
    case "ollama":
      return {
        provider: "ollama",
        baseURL: args.baseUrl || "http://localhost:11434/api",
        apiKey: "", // Ollama ã¯èªè¨¼ä¸è¦
        model: args.model,
      };
    default:
      throw new Error(`ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: ${args.provider}`);
  }
}

// ãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
function createModelClient(config: ProviderConfig) {
  switch (config.provider) {
    case "github":
    case "openrouter":
      return createOpenAI({
        baseURL: config.baseURL,
        apiKey: config.apiKey,
      }).chat(config.model);
    case "ollama":
      return createOllama({
        baseURL: config.baseURL,
      }).chat(config.model);
    default:
      throw new Error(`ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: ${config.provider}`);
  }
}

// ãƒªãƒˆãƒ©ã‚¤è¨­å®šï¼ˆmaxRetriesã®ã¿è¨­å®šå¯èƒ½ï¼‰
const MAX_RETRIES = parseInt(Deno.env.get("MAX_RETRIES") || "3");

async function main() {
  try {
    // ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’è§£æ
    const args = parseCommandLineArgs();

    // ãƒ˜ãƒ«ãƒ—è¡¨ç¤º
    if (args.help) {
      showHelp();
      return;
    }

    // ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®šã‚’ä½œæˆ
    const config = createProviderConfig(args);

    // ãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
    const model = createModelClient(config);

    console.log("=== è¨­å®šæƒ…å ± ===");
    console.log(`ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: ${config.provider}`);
    console.log(`ãƒ¢ãƒ‡ãƒ«: ${config.model}`);
    console.log(`ãƒ™ãƒ¼ã‚¹URL: ${config.baseURL}`);
    console.log(`ãƒªãƒˆãƒ©ã‚¤å›æ•°: ${MAX_RETRIES}`);

    let client;

    try {
      // MCP clientã®è¨­å®šï¼ˆstdio transportä½¿ç”¨ï¼‰
      const transport = new Experimental_StdioMCPTransport({
        command: "deno",
        args: ["run", "/home/kesin/github/kesin11/mcp_sandbox/todo_server.ts"],
      });

      client = await experimental_createMCPClient({
        transport,
      });

      // MCPã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰toolsã‚’å–å¾—
      const tools = await client.tools();

      // ãƒ¢ãƒ‡ãƒ«æƒ…å ±
      console.log("=== ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ« ===");
      console.log(`ãƒ¢ãƒ‡ãƒ«ID: ${config.model}`);

      // AIå‡¦ç†ã®å®Ÿè¡Œ
      // ãƒªãƒˆãƒ©ã‚¤è¨­å®šã®è©³ç´°ï¼š
      // - maxRetries: ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆã‚„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼æ™‚ã®æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ï¼ˆç’°å¢ƒå¤‰æ•°ã§è¨­å®šå¯èƒ½ï¼‰
      // - AI SDKã¯å†…éƒ¨ã§å›ºå®šã®æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã‚’ä½¿ç”¨ï¼ˆåˆæœŸå¾…æ©Ÿæ™‚é–“: 2ç§’ã€ä¿‚æ•°: 2å€ï¼‰
      const response = await generateText({
        model,
        tools,
        maxSteps: 10,
        maxRetries: MAX_RETRIES,
        messages: [
          {
            role: "system",
            content: `ã‚ãªãŸã¯TODOã‚¿ã‚¹ã‚¯ç®¡ç†ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è¦æ±‚ã«å¿œã˜ã¦ã€ä»¥ä¸‹ã®ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã‚¿ã‚¹ã‚¯ã‚’ç®¡ç†ã—ã¦ãã ã•ã„ï¼š

1. create_session: æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆã—ã€åˆæœŸã‚¿ã‚¹ã‚¯ã‚’è¨­å®š
2. get_tasks: ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã®ã‚¿ã‚¹ã‚¯ä¸€è¦§ã‚’å–å¾—
3. update_task_status: æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã®çŠ¶æ…‹ã‚’æ›´æ–°ï¼ˆå®Œäº†/æœªå®Œäº†ï¼‰
4. update_tasks: æŒ‡å®šã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã®è¤‡æ•°ã®ã‚¿ã‚¹ã‚¯ã‚’ä¸€åº¦ã«æ›´æ–°ãƒ»è¿½åŠ 

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã‚’ç†è§£ã—ã€é©åˆ‡ãªé †åºã§ãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã—ã¦ã‚¿ã‚¹ã‚¯ã‚’ç®¡ç†ã—ã€
çµæœã‚’ã‚ã‹ã‚Šã‚„ã™ãæ—¥æœ¬èªã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚`,
          },
          {
            role: "user",
            content: args.message,
          },
        ],
      });

      console.log("=== AI Todo Manager ã®çµæœ ===");
      console.log(response.text);

      // è©³ç´°ãªãƒ­ã‚°ã‚’å‡ºåŠ›
      console.log("\n=== è©³ç´°ãªã‚„ã‚Šå–ã‚Šãƒ­ã‚° ===");
      console.log(`ç·ã‚¹ãƒ†ãƒƒãƒ—æ•°: ${response.steps.length}`);
      console.log(`æœ€çµ‚çµæœ: ${response.finishReason}`);
      console.log(`ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡: ${JSON.stringify(response.usage)}`);

      // å„ã‚¹ãƒ†ãƒƒãƒ—ã®è©³ç´°ã‚’å‡ºåŠ›
      response.steps.forEach((step, index) => {
        console.log(`\n--- ã‚¹ãƒ†ãƒƒãƒ— ${index + 1} (${step.stepType}) ---`);

        if (step.text) {
          console.log(`ãƒ†ã‚­ã‚¹ãƒˆå¿œç­”: ${step.text}`);
        }

        if (step.toolCalls && step.toolCalls.length > 0) {
          console.log("ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—:");
          step.toolCalls.forEach((call, callIndex) => {
            console.log(`  ${callIndex + 1}. ${call.toolName}`);
            console.log(`     å¼•æ•°: ${JSON.stringify(call.args, null, 2)}`);
          });
        }

        if (step.toolResults && step.toolResults.length > 0) {
          console.log("ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµæœ:");
          step.toolResults.forEach((result, resultIndex) => {
            console.log(`  ${resultIndex + 1}. ${result.toolName}`);
            console.log(`     çµæœ: ${JSON.stringify(result.result, null, 2)}`);
          });
        }

        if (step.usage) {
          console.log(`ã‚¹ãƒ†ãƒƒãƒ—ä½¿ç”¨é‡: ${JSON.stringify(step.usage)}`);
        }
      });
    } catch (error) {
      console.error("ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:", error);

      // ãƒªãƒˆãƒ©ã‚¤ã‚¨ãƒ©ãƒ¼ã®è©³ç´°ã‚’è¡¨ç¤º
      if (error instanceof Error && error.name === "RetryError") {
        console.error("=== ãƒªãƒˆãƒ©ã‚¤ã‚¨ãƒ©ãƒ¼ã®è©³ç´° ===");
        const retryError = error as Error & {
          reason?: string;
          errors?: unknown[];
        };
        console.error(`ç†ç”±: ${retryError.reason || "ä¸æ˜"}`);
        console.error(`ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: ${error.message}`);
        console.error(`è©¦è¡Œå›æ•°: ${retryError.errors?.length || "ä¸æ˜"}`);

        if (retryError.errors) {
          console.error("ã‚¨ãƒ©ãƒ¼å±¥æ­´:");
          retryError.errors.forEach((err: unknown, index: number) => {
            const errMessage = err instanceof Error ? err.message : String(err);
            console.error(`  ${index + 1}. ${errMessage}`);
          });
        }
      }

      // ãƒªãƒˆãƒ©ã‚¤ã‚¨ãƒ©ãƒ¼ã®å ´åˆ
      const errorMessage = error instanceof Error
        ? error.message
        : String(error);
      if (errorMessage.includes("rate limit") || errorMessage.includes("429")) {
        console.error(
          "\nğŸ’¡ ãƒ’ãƒ³ãƒˆ: ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆã«é”ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚",
        );
        console.error("ä»¥ä¸‹ã®ç’°å¢ƒå¤‰æ•°ã§è¨­å®šã‚’èª¿æ•´ã—ã¦ãã ã•ã„:");
        console.error(
          "- MAX_RETRIES: ãƒªãƒˆãƒ©ã‚¤å›æ•°ã‚’å¢—ã‚„ã™ï¼ˆç¾åœ¨: " + MAX_RETRIES + "ï¼‰",
        );
        console.error(
          "æ³¨æ„: AI SDKã®å†…éƒ¨ãƒªãƒˆãƒ©ã‚¤è¨­å®šï¼ˆåˆæœŸå¾…æ©Ÿ2ç§’ã€ä¿‚æ•°2å€ï¼‰ã¯å¤‰æ›´ã§ãã¾ã›ã‚“",
        );
        console.error(
          "\nä¾‹: MAX_RETRIES=10 deno run --allow-all ai_sdk_mcp.ts",
        );
      }
    } finally {
      // ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
      await client?.close();
    }
  } catch (error) {
    console.error("åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼:", error);

    if (error instanceof Error && error.message.includes("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æŒ‡å®š")) {
      console.error("\nğŸ’¡ ãƒ’ãƒ³ãƒˆ: ä»¥ä¸‹ã®ã‚ˆã†ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æŒ‡å®šã—ã¦ãã ã•ã„:");
      console.error(
        'deno run --allow-all ai_sdk_mcp.ts "ã‚¿ã‚¹ã‚¯ä½œæˆã—ã¦ãã ã•ã„" --model "openai/gpt-4.1"',
      );
    }

    if (
      error instanceof Error &&
      error.message.includes("--model ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯å¿…é ˆ")
    ) {
      console.error(
        "\nğŸ’¡ ãƒ’ãƒ³ãƒˆ: --model ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«åã‚’æŒ‡å®šã—ã¦ãã ã•ã„:",
      );
      console.error(
        'deno run --allow-all ai_sdk_mcp.ts "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸" --model "openai/gpt-4.1"',
      );
    }
  }
}

// ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒãƒ¡ã‚¤ãƒ³ã§å®Ÿè¡Œã•ã‚ŒãŸå ´åˆã«mainã‚’å‘¼ã³å‡ºã—
if (import.meta.main) {
  main().catch(console.error);
}
